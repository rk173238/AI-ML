{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "62f8ce61367dc6a812b1f7584a1becaa91ac4f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello there, how are you? Weather is awesome. Its raining here now.\"\n",
      "['\"Hello there, how are you?', 'Weather is awesome.', 'Its raining here now.\"']\n",
      "\"Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.\"\n",
      "['\"Hello Mr. Raja, how are you?', 'Weather is awesome.', 'Its raining here now.\"']\n",
      "\"Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.\"\n",
      "['\"Hello Mr. Raja, how are you.', 'Weather is bad.', 'Its heavily raining here now.\"']\n",
      "\"NLP is great technique. It is nice to learn this technique.\"\n",
      "['\"NLP is great technique.', 'It is nice to learn this technique.\"']\n",
      "\"AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.\"\n",
      "['\"AI is making difference in this world now.', 'It would be helpful for betterment of human life.', 'We need to make advantage of that.\"']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hello there, how are you?</td>\n",
       "      <td>Weather is awesome.</td>\n",
       "      <td>Its raining here now.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Hello Mr. Raja, how are you?</td>\n",
       "      <td>Weather is awesome.</td>\n",
       "      <td>Its raining here now.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hello Mr. Raja, how are you.</td>\n",
       "      <td>Weather is bad.</td>\n",
       "      <td>Its heavily raining here now.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"NLP is great technique.</td>\n",
       "      <td>It is nice to learn this technique.\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"AI is making difference in this world now.</td>\n",
       "      <td>It would be helpful for betterment of human life.</td>\n",
       "      <td>We need to make advantage of that.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0                 ...                                                     2\n",
       "0                   \"Hello there, how are you?                 ...                                Its raining here now.\"\n",
       "1                \"Hello Mr. Raja, how are you?                 ...                                Its raining here now.\"\n",
       "2                \"Hello Mr. Raja, how are you.                 ...                        Its heavily raining here now.\"\n",
       "3                     \"NLP is great technique.                 ...                                                   NaN\n",
       "4  \"AI is making difference in this world now.                 ...                   We need to make advantage of that.\"\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLP 1\n",
    "df = pd.read_csv(\"../input/data_in.csv\",index_col=0)\n",
    "df.head()\n",
    "dff = pd.DataFrame(columns=[])\n",
    "ii = 0;\n",
    "from nltk.tokenize import sent_tokenize\n",
    "for i in df.index:\n",
    "    print(i)\n",
    "    sentence = sent_tokenize(i)\n",
    "    print(sentence)\n",
    "    dff = dff.append(pd.Series(sentence), ignore_index=True)\n",
    "\n",
    "dff.to_csv(\"data_out1.csv\",encoding='utf-8', index=False)\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'Hello', 'there', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.', \"''\"]\n",
      "['``', 'Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.', \"''\"]\n",
      "['``', 'Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '.', 'Weather', 'is', 'bad', '.', 'Its', 'heavily', 'raining', 'here', 'now', '.', \"''\"]\n",
      "['``', 'NLP', 'is', 'great', 'technique', '.', 'It', 'is', 'nice', 'to', 'learn', 'this', 'technique', '.', \"''\"]\n",
      "['``', 'AI', 'is', 'making', 'difference', 'in', 'this', 'world', 'now', '.', 'It', 'would', 'be', 'helpful', 'for', 'betterment', 'of', 'human', 'life', '.', 'We', 'need', 'to', 'make', 'advantage', 'of', 'that', '.', \"''\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>``</td>\n",
       "      <td>Hello</td>\n",
       "      <td>there</td>\n",
       "      <td>,</td>\n",
       "      <td>how</td>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>?</td>\n",
       "      <td>Weather</td>\n",
       "      <td>is</td>\n",
       "      <td>awesome</td>\n",
       "      <td>.</td>\n",
       "      <td>Its</td>\n",
       "      <td>raining</td>\n",
       "      <td>here</td>\n",
       "      <td>now</td>\n",
       "      <td>.</td>\n",
       "      <td>''</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>``</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Raja</td>\n",
       "      <td>,</td>\n",
       "      <td>how</td>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>?</td>\n",
       "      <td>Weather</td>\n",
       "      <td>is</td>\n",
       "      <td>awesome</td>\n",
       "      <td>.</td>\n",
       "      <td>Its</td>\n",
       "      <td>raining</td>\n",
       "      <td>here</td>\n",
       "      <td>now</td>\n",
       "      <td>.</td>\n",
       "      <td>''</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>``</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Raja</td>\n",
       "      <td>,</td>\n",
       "      <td>how</td>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>.</td>\n",
       "      <td>Weather</td>\n",
       "      <td>is</td>\n",
       "      <td>bad</td>\n",
       "      <td>.</td>\n",
       "      <td>Its</td>\n",
       "      <td>heavily</td>\n",
       "      <td>raining</td>\n",
       "      <td>here</td>\n",
       "      <td>now</td>\n",
       "      <td>.</td>\n",
       "      <td>''</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>``</td>\n",
       "      <td>NLP</td>\n",
       "      <td>is</td>\n",
       "      <td>great</td>\n",
       "      <td>technique</td>\n",
       "      <td>.</td>\n",
       "      <td>It</td>\n",
       "      <td>is</td>\n",
       "      <td>nice</td>\n",
       "      <td>to</td>\n",
       "      <td>learn</td>\n",
       "      <td>this</td>\n",
       "      <td>technique</td>\n",
       "      <td>.</td>\n",
       "      <td>''</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>``</td>\n",
       "      <td>AI</td>\n",
       "      <td>is</td>\n",
       "      <td>making</td>\n",
       "      <td>difference</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>world</td>\n",
       "      <td>now</td>\n",
       "      <td>.</td>\n",
       "      <td>It</td>\n",
       "      <td>would</td>\n",
       "      <td>be</td>\n",
       "      <td>helpful</td>\n",
       "      <td>for</td>\n",
       "      <td>betterment</td>\n",
       "      <td>of</td>\n",
       "      <td>human</td>\n",
       "      <td>life</td>\n",
       "      <td>.</td>\n",
       "      <td>We</td>\n",
       "      <td>need</td>\n",
       "      <td>to</td>\n",
       "      <td>make</td>\n",
       "      <td>advantage</td>\n",
       "      <td>of</td>\n",
       "      <td>that</td>\n",
       "      <td>.</td>\n",
       "      <td>''</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2       3           4  ...          24   25    26   27   28\n",
       "0  ``  Hello  there       ,         how ...         NaN  NaN   NaN  NaN  NaN\n",
       "1  ``  Hello    Mr.    Raja           , ...         NaN  NaN   NaN  NaN  NaN\n",
       "2  ``  Hello    Mr.    Raja           , ...         NaN  NaN   NaN  NaN  NaN\n",
       "3  ``    NLP     is   great   technique ...         NaN  NaN   NaN  NaN  NaN\n",
       "4  ``     AI     is  making  difference ...   advantage   of  that    .   ''\n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLP 2\n",
    "df = pd.read_csv(\"../input/data_in.csv\",index_col=0)\n",
    "dff = pd.DataFrame(columns=[])\n",
    "from nltk.tokenize import word_tokenize\n",
    "for i in df.index:\n",
    "    word = word_tokenize(i)\n",
    "    print(word)\n",
    "    dff = dff.append(pd.Series(word), ignore_index=True)\n",
    "\n",
    "dff.to_csv(\"data_out2.csv\",encoding='utf-8', index=False)\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d59b7c0160252dd7ca779c6f3850f2a1eda9ad76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  ``/``\n",
      "  Hello/NNP\n",
      "  there/RB\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ?/.\n",
      "  Weather/''\n",
      "  is/VBZ\n",
      "  awesome/JJ\n",
      "  ./.\n",
      "  Its/PRP$\n",
      "  raining/VBG\n",
      "  here/RB\n",
      "  now/RB\n",
      "  ./.\n",
      "  ''/'')\n",
      "(S\n",
      "  ``/``\n",
      "  (PERSON Hello/NNP Mr./NNP Raja/NNP)\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ?/.\n",
      "  Weather/''\n",
      "  is/VBZ\n",
      "  awesome/JJ\n",
      "  ./.\n",
      "  Its/PRP$\n",
      "  raining/VBG\n",
      "  here/RB\n",
      "  now/RB\n",
      "  ./.\n",
      "  ''/'')\n",
      "(S\n",
      "  ``/``\n",
      "  (PERSON Hello/NNP Mr./NNP Raja/NNP)\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ./.\n",
      "  Weather/CC\n",
      "  is/VBZ\n",
      "  bad/JJ\n",
      "  ./.\n",
      "  Its/PRP$\n",
      "  heavily/RB\n",
      "  raining/VBG\n",
      "  here/RB\n",
      "  now/RB\n",
      "  ./.\n",
      "  ''/'')\n",
      "(S\n",
      "  ``/``\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  is/VBZ\n",
      "  great/JJ\n",
      "  technique/NN\n",
      "  ./.\n",
      "  It/PRP\n",
      "  is/VBZ\n",
      "  nice/JJ\n",
      "  to/TO\n",
      "  learn/VB\n",
      "  this/DT\n",
      "  technique/NN\n",
      "  ./.\n",
      "  ''/'')\n",
      "(S\n",
      "  ``/``\n",
      "  AI/NNP\n",
      "  is/VBZ\n",
      "  making/VBG\n",
      "  difference/NN\n",
      "  in/IN\n",
      "  this/DT\n",
      "  world/NN\n",
      "  now/RB\n",
      "  ./.\n",
      "  It/PRP\n",
      "  would/MD\n",
      "  be/VB\n",
      "  helpful/JJ\n",
      "  for/IN\n",
      "  betterment/NN\n",
      "  of/IN\n",
      "  human/JJ\n",
      "  life/NN\n",
      "  ./.\n",
      "  We/PRP\n",
      "  need/VBP\n",
      "  to/TO\n",
      "  make/VB\n",
      "  advantage/NN\n",
      "  of/IN\n",
      "  that/DT\n",
      "  ./.\n",
      "  ''/'')\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "no display name and no $DISPLAY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-90d70e7927cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mdraw_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[0;34m(*trees)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \"\"\"\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mTreeView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *trees)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLTK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-x>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2018\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2020\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2021\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
     ]
    }
   ],
   "source": [
    "#NLP 3\n",
    "df = pd.read_csv(\"../input/data_in.csv\",index_col=0)\n",
    "for line in df.index:\n",
    "    word = nltk.word_tokenize(line)\n",
    "    token = nltk.pos_tag(word)\n",
    "    #print(token)\n",
    "    c = nltk.ne_chunk(token)\n",
    "    print(c)\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "254c6f4e0e7c6a408f9d7aee19d19bd0e0c8f530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`` `` True\n",
      "hello hello True\n",
      ", , True\n",
      "? ? True\n",
      "weather weather True\n",
      "awesom awesome False\n",
      ". . True\n",
      "it its False\n",
      "rain raining False\n",
      ". . True\n",
      "'' '' True\n",
      "`` `` True\n",
      "hello hello True\n",
      "mr. mr. True\n",
      "raja raja True\n",
      ", , True\n",
      "? ? True\n",
      "weather weather True\n",
      "awesom awesome False\n",
      ". . True\n",
      "it its False\n",
      "rain raining False\n",
      ". . True\n",
      "'' '' True\n",
      "`` `` True\n",
      "hello hello True\n",
      "mr. mr. True\n",
      "raja raja True\n",
      ", , True\n",
      ". . True\n",
      "weather weather True\n",
      "bad bad True\n",
      ". . True\n",
      "it its False\n",
      "heavili heavily False\n",
      "rain raining False\n",
      ". . True\n",
      "'' '' True\n",
      "`` `` True\n",
      "nlp nlp True\n",
      "great great True\n",
      "techniqu technique False\n",
      ". . True\n",
      "it it True\n",
      "nice nice True\n",
      "learn learn True\n",
      "techniqu technique False\n",
      ". . True\n",
      "'' '' True\n",
      "`` `` True\n",
      "ai ai True\n",
      "make making False\n",
      "differ difference False\n",
      "world world True\n",
      ". . True\n",
      "it it True\n",
      "would would True\n",
      "help helpful False\n",
      "better betterment False\n",
      "human human True\n",
      "life life True\n",
      ". . True\n",
      "we we True\n",
      "need need True\n",
      "make make True\n",
      "advantag advantage False\n",
      ". . True\n",
      "'' '' True\n"
     ]
    }
   ],
   "source": [
    "#NLP 4\n",
    "from nltk.corpus import stopwords \n",
    "df = pd.read_csv(\"../input/data_in.csv\",index_col=0)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sw = []\n",
    "#exclude stop word\n",
    "for line in df.index:\n",
    "    word = nltk.word_tokenize(line)\n",
    "    for w in word:\n",
    "        if w not in stop_words:\n",
    "            sw.append(w)\n",
    "#end stopwords\n",
    "#stemming\n",
    "from nltk import stem\n",
    "w_l = stem.WordNetLemmatizer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "ps = SnowballStemmer('english')\n",
    "for w in sw :\n",
    "    st = ps.stem(w)\n",
    "    lm = (w_l.lemmatize(w)).lower()\n",
    "    print(st,lm,lm==st)\n",
    "#end lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c2508bb5b13e63e38b196db44009e9fffb17de4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#NLP 5\n",
    "#../input/sent.txt\n",
    "sent = {}\n",
    "for line in open('../input/sent.txt'):\n",
    "    word,score = line.split(\"\\t\")\n",
    "    sent[word] = int(score)\n",
    "\n",
    "df = pd.read_csv(\"../input/data_in.csv\",index_col=0)\n",
    "for line in df.index:\n",
    "    print(sum(sent.get(word,0)for word in line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
